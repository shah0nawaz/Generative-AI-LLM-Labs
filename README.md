# In-Context learning and text Summarization Using Large Language Models (flan-T5 LLM)


In-context learning is very inexpensive method for learning LLMs, which sometimes works for deverse set of simple applications.

In this article we are dicussiong different inference methods of LLMs.

- Without prompt engineering
- Zero-shot
- One-shot
- Few-shot
- setting model configuration

  **1. Without In-Context Learning in LLM Inference:**
  Without in-context learning, an LLM performs inference based purely on the patterns it has learned during pre-training. It does not leverage the specific context or instructions provided in the input prompt, which is typically how in-context learning enhances the modelâ€™s performance in tasks like text completion, question answering, or reasoning.
  
